# Toxic comment classification projet

## Problem statement

The goal of this project is to build a classification model that allows to detect different types of toxicity (obscenity, threats, insults, and identity-based hate). 

The initial project and data come from the [Conversation AI team](https://conversationai.github.io/), a research initiative founded by [Jigsaw](https://jigsaw.google.com/) and Google (both a part of Alphabet). They are working on tools to help improve online conversations. One area of focus is the study of negative online behaviors, like toxic comments (i.e. comments that are rude, disrespectful or otherwise likely to make someone leave a discussion)

## Data sets

The data is available on [Kaggle competition](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)

## Project requirements

numpy
pandas
matplotlib.pyplot
seaborn
sklearn
keras
tensorflow
wordcloud
imblearn
